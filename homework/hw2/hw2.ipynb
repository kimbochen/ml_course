{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2: k-NN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define column names\n",
    "names = ['a', 'b', 'c', 'd', 'class']\n",
    "\n",
    "# Read CSV file\n",
    "df = pd.read_csv('iris.data.txt', header=None, names=names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-NN Algorithm\n",
    "\n",
    "The algorithm is implemented with vectorization in mind.\n",
    "\n",
    "1. Square of difference matrix $${S} = {X} - \\begin{bmatrix} X_{t} \\\\ X_{t} \\\\ \\vdots \\\\ X_{t} \\\\\\end{bmatrix}$$\n",
    "   Each element is then squared.\n",
    "\n",
    "2. Euclidean distance is the sum of all columns of ${S}$.\n",
    "   $${D} = {S}\\begin{bmatrix} 1 \\\\ 1 \\\\ \\vdots \\\\ 1 \\\\\\end{bmatrix}$$\n",
    "\n",
    "3. Selection is implemented by doing k partition on ${D}$.\n",
    "\n",
    "4. The indices of the selected ones is stored in `select`, which is passed to `y` to access their corresponding classes.\n",
    "   \n",
    "   `np.unique` passes each element and the number of times it was counted to `lablel` and `freq`.\n",
    "   \n",
    "   Return the element who has the most number of times counted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_classifier(df, Xt, k):\n",
    "    '''Given dataset (X, y), classifies object Xt using k-NN algorithm.'''\n",
    "    # Split up features and labels\n",
    "    X = np.float32(df.iloc[:, 0:4])\n",
    "    y = np.array(df['class'])\n",
    "    \n",
    "    # Convert test example into float numpy array\n",
    "    Xt =  np.float32(Xt.iloc[0:4]).reshape((1, -1))\n",
    "\n",
    "    m, n = X.shape\n",
    "\n",
    "    # Square of difference for each element\n",
    "    sqdiff = (X - np.ones((m, 1)) @ Xt) ** 2\n",
    "\n",
    "    # Euclidean distance for every row\n",
    "    dist = np.sqrt(sqdiff @ np.ones((n, 1)))\n",
    "\n",
    "    # Selection of k smallest distance\n",
    "    select = np.argpartition(dist, k, axis=0)[:k]\n",
    "\n",
    "    # Find the dominant label among the selection\n",
    "    label, freq = np.unique(y[select], return_counts=True)\n",
    "\n",
    "    return label[freq.argmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    "I took an example from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Iris-virginica'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test data: label='Iris-virginica'\n",
    "Xt = pd.DataFrame(np.array([\n",
    "    [6.7,3.0,5.2,2.3]\n",
    "]))\n",
    "\n",
    "# Perform k-NN Classification\n",
    "knn_classifier(df, Xt, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "\n",
    "1. Split the DataFrame into 2 sets: one contains 60% of each class example, the other contains the rest.\n",
    "\n",
    "2. The prediction function is a lambda function that calls `knn_classifier` and compares the result with the answer.\n",
    "\n",
    "3. `test_set.apply` applies the function to each row with vectorization.\n",
    "\n",
    "4. `np.count_nonzero` counts number of successful predictions in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: 58\n",
      "Failure: 2\n",
      "Accuracy: 0.967\n"
     ]
    }
   ],
   "source": [
    "# Split DataFrame into training set and testing set\n",
    "train_set = pd.concat([\n",
    "    df.iloc[0:30, :], \n",
    "    df.iloc[50:80, :], \n",
    "    df.iloc[100:130, :]\n",
    "])\n",
    "\n",
    "test_set = pd.concat([\n",
    "    df.iloc[30:50, :],\n",
    "    df.iloc[80:100, :],\n",
    "    df.iloc[130:150, :]\n",
    "])\n",
    "\n",
    "# Prediction function\n",
    "f = lambda Xt: knn_classifier(train_set, Xt, 1) == Xt.iloc[-1]\n",
    "\n",
    "# Apply function to each row of testing set \n",
    "pred = test_set.apply(pred, axis=1)\n",
    "\n",
    "# Count number of successful predictions\n",
    "stat = np.count_nonzero(pred)\n",
    "\n",
    "print(f'Success: {stat}\\nFailure: {test_set.shape[0] - stat}\\nAccuracy: {stat / test_set.shape[0]:.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (mlcourse)",
   "language": "python",
   "name": "mlcourse-e661j8pj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
